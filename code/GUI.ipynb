{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "!pip install tensorflow pillow\n",
    "!pip install opencv-python"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:16:56.858841Z",
     "start_time": "2024-06-21T05:16:50.585013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import string\n",
    "import os"
   ],
   "id": "4afe1be6b4102e8f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:16:59.761113Z",
     "start_time": "2024-06-21T05:16:59.488819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tải mô hình đã lưu ở định dạng .h5\n",
    "file_path = r'D:\\hoc\\main\\study\\HK6\\Xu_Ly_Anh\\btl\\Recognize_handwriting\\mymodel.h5'\n",
    "if os.path.exists(file_path):\n",
    "    model = tf.keras.models.load_model(file_path)\n",
    "    # Biên dịch lại mô hình để tránh cảnh báo\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "else:\n",
    "    print(f\"File not found: {file_path}\")"
   ],
   "id": "63d4bce400d3891f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HoNamTu\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:17:58.327421Z",
     "start_time": "2024-06-21T05:17:58.317975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hàm giải mã nhãn thành chữ cái\n",
    "def decoder_label(arr):\n",
    "    alphabet = list(string.ascii_lowercase)\n",
    "    dict_label = {i: alphabet[i] for i in range(26)}\n",
    "    decoded_arr = [dict_label[i] for i in arr]\n",
    "    decoded_string = ''.join(decoded_arr)\n",
    "    return decoded_string"
   ],
   "id": "ae923afe553d1632",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:18:01.493193Z",
     "start_time": "2024-06-21T05:18:01.485249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def x_cord_contour(contours):\n",
    "    if cv2.contourArea(contours) > 10:\n",
    "        M = cv2.moments(contours)\n",
    "        return int(M['m10']/M['m00'])\n",
    "    else:\n",
    "        pass\n"
   ],
   "id": "a2b9e5a8b64198eb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:18:02.499606Z",
     "start_time": "2024-06-21T05:18:02.493563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def crop_define(path):\n",
    "    img = cv2.imread(path)\n",
    "    img1 = cv2.imread(path, 0)\n",
    "    resized_img = cv2.resize(img1, (4250, 3450))\n",
    "    crop_img = resized_img[1000:2500, 250:4000]\n",
    "    reco_letters(crop_img)"
   ],
   "id": "9e1f07d5af30daf2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:18:04.278016Z",
     "start_time": "2024-06-21T05:18:04.261050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reco_letters(img):\n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    cnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < 800:\n",
    "            cv2.drawContours(thresh, [c], -1, (0, 0, 0), -1)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours_left_to_right = sorted(contours, key=x_cord_contour, reverse=False)\n",
    "    preprocessed_letter = []\n",
    "    for (i, c) in enumerate(contours_left_to_right):\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), color=(0, 0, 0), thickness=2)\n",
    "        digit = thresh[y:y+h, x:x+w]\n",
    "        resized_digit = cv2.resize(digit, (18, 18))\n",
    "        padded_digit = np.pad(resized_digit, ((5, 5), (5, 5)), \"constant\", constant_values=0)\n",
    "        preprocessed_letter.append(padded_digit)\n",
    "    processed_letter = []\n",
    "    for digit in preprocessed_letter:\n",
    "        prediction = model.predict(digit.reshape(1, 28, 28, 1))\n",
    "        processed_letter.append(np.argmax(prediction))\n",
    "    arr = np.array(processed_letter)\n",
    "    decoded_string = decoder_label(arr)\n",
    "    result_text.set(f\"Predicted Text: {decoded_string}\")\n",
    "    \n",
    "    # Cập nhật hình ảnh trong GUI\n",
    "    img_display = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    img_display = img_display.resize((425, 345))\n",
    "    img_display = ImageTk.PhotoImage(img_display)\n",
    "    panel_image.configure(image=img_display)\n",
    "    panel_image.image = img_display"
   ],
   "id": "d3a10b7a85468abb",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:18:05.327141Z",
     "start_time": "2024-06-21T05:18:05.316392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img = Image.open(file_path).convert('L')\n",
    "        img = img.resize((425, 345))\n",
    "        img = ImageTk.PhotoImage(img)\n",
    "        panel_image.configure(image=img)\n",
    "        panel_image.image = img\n",
    "        crop_define(file_path)"
   ],
   "id": "338078ff593fa46d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:18:22.098980Z",
     "start_time": "2024-06-21T05:18:06.396455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tạo giao diện chính\n",
    "root = tk.Tk()\n",
    "root.title(\"Handwritten Character Recognition\")\n",
    "#root.attributes('-fullscreen', True)\n",
    "\n",
    "# Khung hình ảnh lớn\n",
    "canvas = tk.Canvas(root, width=425, height=345)\n",
    "canvas.pack()\n",
    "\n",
    "panel_image = tk.Label(canvas)\n",
    "panel_image.pack()\n",
    "\n",
    "load_button = tk.Button(root, text=\"Load Image\", command=load_image)\n",
    "load_button.pack()\n",
    "\n",
    "# Khung hiển thị kết quả\n",
    "result_frame = tk.Frame(root, bd=2, relief=\"solid\")\n",
    "result_frame.pack(pady=20)\n",
    "result_text = tk.StringVar()\n",
    "result_label = tk.Label(result_frame, textvariable=result_text, font=(\"Helvetica\", 20, \"bold\"))\n",
    "result_label.pack()\n",
    "\n",
    "root.mainloop()"
   ],
   "id": "b557528e8160b1c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 267ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "43fb6a252b0c3338"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
