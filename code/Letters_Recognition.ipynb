{"cells":[{"cell_type":"markdown","metadata":{"id":"hEcH21X-VRxA"},"source":["# Khai báo các thư viện cần sử dụng."]},{"cell_type":"code","source":["!pip install keras numpy\n","!pip install tensorflow\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NDohBFN4cxL4","executionInfo":{"status":"ok","timestamp":1715053576798,"user_tz":-420,"elapsed":13791,"user":{"displayName":"Tú Hồ Nam","userId":"14093093823785954521"}},"outputId":"cb4d6a01-1e5c-4a5d-f00c-0a17abc0fb7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"shK8B01pVRxD"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import os\n","import string\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","from google.colab import drive"]},{"cell_type":"code","source":["# mount drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"YF4MLDzB8YWS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lr1Kh0vdVRxF"},"source":["# Load dữ liệu EMNIST."]},{"cell_type":"code","source":["# Load EMNIST dataset\n","\n","# Đọc dữ liệu từ các tập tin CSV\n","file_csv_path = ('/content/drive/My Drive/Colab Notebooks/XuLyAnh/BTL/Handwritten_Data.csv')  # Đường dẫn đến tập tin CSV huấn luyện\n","\n","# Đọc dữ liệu từ CSV\n","data = pd.read_csv(file_csv_path)\n","\n","X = data.iloc[:, 1:].values  # Các cột còn lại là các giá trị pixel\n","y = data.iloc[:, 0].values  # Cột đầu tiên là nhãn\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","print(X_train.shape)\n","print(X_test.shape)\n","\n","# Đảm bảo rằng dữ liệu có kích thước chính xác (28x28)\n","X_train = X_train.reshape(-1, 28, 28)  # Định hình lại thành các hình ảnh 28x28\n","X_test = X_test.reshape(-1, 28, 28)  # Định hình lại thành các hình ảnh 28x28\n","\n","print(X_train.shape)\n","print(X_test.shape)\n"],"metadata":{"id":"C9R0Ekno7jzP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"50CM6nWUVRxF"},"outputs":[],"source":["X_val, y_val = X_train[200000:260000,:], y_train[200000:260000]\n","X_train, y_train = X_train[:370000,:], y_train[:370000]\n","\n","print(X_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"ui82WeKMVRxG"},"source":["# Reshape lại dữ liệu cho đúng kích thước mà keras yêu cầu."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-r9-q2GSVRxG"},"outputs":[],"source":["X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n","X_val = X_val.reshape(X_val.shape[0], 28, 28, 1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n","\n","print (\"Shape of X_train: {}\".format(X_train.shape))\n","print (\"Shape of y_train: {}\".format(y_train.shape))\n","\n","print (\"Shape of X_test: {}\".format(X_test.shape))\n","print (\"Shape of y_test: {}\".format(y_test.shape))"]},{"cell_type":"code","source":["example = X_train[50]\n","plt.imshow(example.reshape(28, 28), cmap=\"gray\")\n","plt.show()"],"metadata":{"id":"Y5JTCknRmHIp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A34oTbhaVRxH"},"source":["# Áp dụng thuật toán One hot encoding label (Y)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rCBpABKyVRxH"},"outputs":[],"source":["lett_classes = 27\n","Y_train = to_categorical(y_train, lett_classes)\n","Y_val = to_categorical(y_val, lett_classes)\n","Y_test = to_categorical(y_test, lett_classes)\n","\n","print('Dữ liệu y ban đầu ', y_train[0])\n","print('Dữ liệu y sau one-hot encoding ',Y_train[0])"]},{"cell_type":"markdown","metadata":{"id":"lxq9u-pSVRxH"},"source":["# Định nghĩa model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dYUjX4k1VRxI"},"outputs":[],"source":["model = Sequential()\n","\n","# Thêm Convolutional layer với 32 kernel, kích thước kernel 3*3.\n","model.add(Conv2D(32, (3, 3), activation='sigmoid', input_shape=(28,28,1)))\n","\n","# Thêm Convolutional layer.\n","model.add(Conv2D(32, (3, 3), activation='sigmoid'))\n","\n","# Thêm Max pooling layer.\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","# Flatten layer chuyển từ tensor sang vector.\n","model.add(Flatten())\n","\n","# Thêm Fully Connected layer với 128 nodes và dùng hàm sigmoid.\n","model.add(Dense(128, activation='sigmoid'))\n","\n","# Output layer với 10 node và dùng softmax function để chuyển sang xác suất.\n","model.add(Dense(27, activation='softmax'))"]},{"cell_type":"markdown","metadata":{"id":"dj955B2_VRxI"},"source":["# Compile model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zmQ_tKJdVRxJ"},"outputs":[],"source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"KZ_eewdlVRxJ"},"source":["# Thực hiện train model với data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vr1XeftaVRxJ"},"outputs":[],"source":["H = model.fit(X_train, Y_train, validation_data=(X_val, Y_val),\n","batch_size=32, epochs=10, verbose=1)"]},{"cell_type":"code","source":["# 8. Vẽ đồ thị loss, accuracy của traning set và validation set\n","fig = plt.figure()\n","numOfEpoch = 10\n","plt.plot(np.arange(0, numOfEpoch), H.history['loss'], label='training loss')\n","plt.plot(np.arange(0, numOfEpoch), H.history['val_loss'], label='validation loss')\n","plt.plot(np.arange(0, numOfEpoch), H.history['accuracy'], label='accuracy')\n","plt.plot(np.arange(0, numOfEpoch), H.history['val_accuracy'], label='validation accuracy')\n","plt.title('Accuracy and Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss|Accuracy')\n","plt.legend()"],"metadata":{"id":"KBB_6Pr0jzRe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hdrd7rLbVRxK"},"source":["# Đánh giá model với dữ liệu test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P-0TMGlMVRxK"},"outputs":[],"source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print(score)"]},{"cell_type":"markdown","metadata":{"id":"5T7FXV7fVRxK"},"source":["# Lưu model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_FqP9WPYVRxK"},"outputs":[],"source":["model.save('/content/drive/My Drive/Colab Notebooks/XuLyAnh/BTL/mymodel.tflearn')"]},{"cell_type":"markdown","metadata":{"id":"zWv9KitsVRxL"},"source":["# Dự đoán kết quả với tệp Test của EMNIST."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ebM9b9_IVRxL"},"outputs":[],"source":["example = X_train[50]\n","\n","prediction = model.predict(example.reshape(1, 28, 28, 1))\n","\n","print(\"\\n\\nFinal Output: {}\".format(np.argmax(prediction)))\n","decoder_label([np.argmax(prediction)])\n","plt.imshow(example.reshape(28, 28), cmap=\"gray\")\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"FbxwP003VRxM"},"source":["# Gọi lại model đã train"]},{"cell_type":"code","source":["model = tf.keras.models.load_model('/content/drive/My Drive/Colab Notebooks/XuLyAnh/BTL/mymodel.tflearn')"],"metadata":{"id":"ijH5gjubAE0S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Giải mã"],"metadata":{"id":"8NrhzgfwHciZ"}},{"cell_type":"code","source":["def decoder_label(arr):\n","  alphabet = list(string.ascii_lowercase)  # ['a', 'b', 'c', ..., 'z']\n","\n","  # Tạo dictionary để ánh xạ số thứ tự với chữ cái\n","  dict_label = {i: alphabet[i] for i in range(26)}\n","\n","  # Giải mã mảng số thành các chữ cái\n","  decoded_arr = [dict_label[i] for i in arr]\n","\n","  # Chuyển mảng chữ cái thành chuỗi\n","  decoded_string = ''.join(decoded_arr)\n","\n","  # In kết quả\n","  print(\"Kết quả nhận dạng giải mã: \", decoded_string)"],"metadata":{"id":"9MGEkNDgH1AB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dự đoán kết quả với tệp Test của EMNIST sau khi gọi lại Model."],"metadata":{"id":"N5xOSF-MT76F"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPrtkNrIVRxL"},"outputs":[],"source":["example = X_train[20]\n","\n","prediction = model.predict(example.reshape(1, 28, 28, 1))\n","print(\"\\n\\nFinal Output: {}\".format(np.argmax(prediction)))\n","decoder_label([np.argmax(prediction)])\n","\n","plt.imshow(example.reshape(28, 28), cmap=\"gray\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"VV_K0qKwVRxN"},"source":["# Minh họa xử lý ảnh và chuẩn bị số liệu (Not care about it)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Djw3NkYBVRxN"},"outputs":[],"source":["    # Đọc ảnh vào\n","    img_path = '/content/drive/My Drive/Colab Notebooks/XuLyAnh/BTL/test6.png'\n","    img = cv2.imread(img_path)\n","    img1 = cv2.imread(img_path,0)\n","\n","    # Resize ảnh\n","    resized_img = cv2.resize(img1, (4250, 3450))\n","\n","    # Hiển thị ảnh gốc\n","    print('original_image')\n","    plt.imshow(img)\n","    plt.axis('off')\n","    plt.show()\n","\n","    # Hiển thị ảnh xám\n","    print('\\n\\ngrayscale_image')\n","    plt.imshow(img1)\n","    plt.show()\n","\n","    # Hiển thị ảnh resize\n","    print('\\n\\nresized_image')\n","    plt.imshow(resized_img)\n","    plt.show()\n","\n","    # Cắt ảnh\n","    crop_img = resized_img[1000:2500, 250:4000]\n","\n","    # Hiển thị ảnh đã cắt\n","    print('\\n\\ncrop_image')\n","    plt.imshow(crop_img)\n","    plt.show()\n","\n","    # Gaussian blur, Otsu's threshold\n","    blur = cv2.GaussianBlur(crop_img, (5,5), 0)\n","    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","\n","    # xử lý điểm ảnh nhỏ\n","    cnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n","    for c in cnts:\n","        area = cv2.contourArea(c)\n","        if area < 800:\n","            cv2.drawContours(thresh, [c], -1, (0,0,0), -1)\n","\n","    # Hiển thị ảnh sau xử lý Gaussian blur\n","    print('\\n\\nGaussian blur')\n","    plt.imshow(blur)\n","    plt.show()\n","\n","    # Hiển thị ảnh sau xử lý Otsu's threshold và điểm ảnh nhỏ\n","    print('\\n\\nOtsu threshold')\n","    plt.imshow(thresh)\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"r23sHy9oVRxL"},"source":["# Sắp xếp viền theo trục x."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PObIqOaGVRxM"},"outputs":[],"source":["def x_cord_contour(contours):\n","    if cv2.contourArea(contours) > 10:\n","        M = cv2.moments(contours)\n","        return (int(M['m10']/M['m00']))\n","    else:\n","        pass"]},{"cell_type":"markdown","metadata":{"id":"D5CP9tyPVRxN"},"source":["# Hàm cắt ảnh và hiển thị kết quả từ ảnh được chọn."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TqGo5VSNVRxN"},"outputs":[],"source":["def crop_define(path):\n","\n","    # Đọc và biểu diễn ảnh từ đường dẫn:\n","    img = cv2.imread(path)\n","    img1 = cv2.imread(path,0)\n","\n","    resized_img = cv2.resize(img1, (4250, 3450))\n","\n","    plt.imshow(img)\n","    plt.axis('off')\n","    plt.show()\n","\n","    # x,y là chỉ số tọa độ trục x và y, w là width, h là height.\n","    crop_img = resized_img[1000:2500, 250:4000] #[y:y+h, x:x+w]\n","\n","    reco_letters(crop_img) # Kết quả"]},{"cell_type":"markdown","metadata":{"id":"nk9d2JHFVRxM"},"source":["# Hàm nhận dạng chữ cái và xuất file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csbuzIt_VRxM"},"outputs":[],"source":["def reco_letters(img):\n","\n","    # Gaussian blur, Otsu's threshold\n","    blur = cv2.GaussianBlur(img, (5,5), 0)\n","    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","\n","    # xử lý điểm ảnh nhỏ\n","    cnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n","    for c in cnts:\n","        area = cv2.contourArea(c)\n","        if area < 800:\n","            cv2.drawContours(thresh, [c], -1, (0,0,0), -1)\n","\n","    # findContour dùng để cung cấp đường viền từng chữ cái trên ảnh.\n","    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","    # Sắp xếp đường viền từ trái sang phải dựa trên hàm sắp xếp đường viền theo trục x.\n","    contours_left_to_right = sorted(contours, key = x_cord_contour, reverse = False)\n","\n","    preprocessed_letter = []\n","\n","    for (i,c)  in enumerate(contours_left_to_right):\n","        (x, y, w, h) = cv2.boundingRect(c)\n","\n","        # tạo viền quanh chữ cái trong ảnh.\n","        cv2.rectangle(img, (x,y), (x+w, y+h), color=(0,0,0), thickness=2)\n","\n","        # cắt ảnh và xử lý\n","        digit = thresh[y:y+h, x:x+w]\n","\n","        # chuyển về size(18,18)\n","        resized_digit = cv2.resize(digit, (18,18))\n","\n","        # thêm padding 5 pixel màu đen vào 4 góc để chuyển ảnh về (28,28)\n","        padded_digit = np.pad(resized_digit, ((5,5),(5,5)), \"constant\", constant_values=0)\n","\n","        # lưu trữ vào preprocessed_letter\n","        preprocessed_letter.append(padded_digit)\n","\n","    # Biểu diễn ảnh sau khi tìm được viền các chữ.\n","    print(\"\\n\\n\\n\")\n","    plt.imshow(img, cmap='gray')\n","    plt.axis('off')\n","    plt.show()\n","\n","    # Dự đoán kết quả.\n","    processed_letter = []\n","\n","    for digit in preprocessed_letter:\n","        prediction = model.predict(digit.reshape(1, 28, 28, 1))\n","\n","        processed_letter.append(np.argmax(prediction))\n","\n","    # In các chữ cái cần nhận dạng: (Kết quả)\n","    arr = np.array(processed_letter)\n","    print('Kết quả nhận dạng mã hóa: ',arr)\n","    decoder_label(arr)\n"]},{"cell_type":"markdown","metadata":{"id":"vmVzYskTVRxN"},"source":["# Test chương trình với một số bằng tốt nghiệp."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FSC_4ZjLVRxO"},"outputs":[],"source":["crop_define('/content/drive/My Drive/Colab Notebooks/XuLyAnh/BTL/test5.png')"]},{"cell_type":"code","source":["crop_define('/content/drive/My Drive/Colab Notebooks/XuLyAnh/BTL/test6.png')"],"metadata":{"id":"2ax5CCGxWhmC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Link full project"],"metadata":{"id":"l-J_laqFjU8C"}},{"cell_type":"markdown","source":["https://drive.google.com/drive/folders/1BDu3baDpv42pB5ISQV-zLcyavcS_q3T3?usp=sharing"],"metadata":{"id":"HUSrCfLBjxcd"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.15"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}